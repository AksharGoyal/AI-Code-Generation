{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBtzYNKIYSrX"
      },
      "source": [
        "## Text Generation using GPT2 model\n",
        "\n",
        "### Project: Ads generation from product description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6s4W2FuuGX5",
        "outputId": "8f17aa0d-d33d-45de-8813-73fae415d96f"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers accelerate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8jLjk9lzyLZc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2L9DzTkyXN6",
        "outputId": "b28db352-1eb9-4391-c084-3a64ce42a89b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "395d9f4fdbe34a45b0b7f3a53bbd4b70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\claim\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\claim\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3aee85881b2d48ba8304c6fc585d88ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fd1e1886d314dc2801d34af090051a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3300d251860c4901a2df4dfcb5401662",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"gpt2-large\"  #or just gpt2\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = TFGPT2LMHeadModel.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9SeocY-_0r0A"
      },
      "outputs": [],
      "source": [
        "def generate_advertisement(product_description, max_length=100):\n",
        "    input_text = \"Product: \" + product_description + \"\\nAdvertisement:\"\n",
        "\n",
        "    # Encode input text into ids- tokenization\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"tf\")\n",
        "\n",
        "    # Generate text\n",
        "    output = model.generate(input_ids, max_length=max_length)\n",
        "\n",
        "    # decode the ids back into text\n",
        "    generated_ads = []\n",
        "    for sample in output:\n",
        "        generated_ad = tokenizer.decode(sample, skip_special_tokens=True)\n",
        "        generated_ads.append(generated_ad)\n",
        "\n",
        "    return generated_ads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PjeLyGGQ1zJx"
      },
      "outputs": [],
      "source": [
        "product_description = \"Introducing our latest smartphone model, with a powerful processor and stunning camera features.\"\n",
        "\n",
        "# Generate advertisements\n",
        "generated_ads = generate_advertisement(product_description, max_length=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD8yL82RhXNy"
      },
      "source": [
        "### Predicted response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YBcZoa813gi",
        "outputId": "fca22b7c-4cb1-4050-8c4d-2b90778d079c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Product: Introducing our latest smartphone model, with a powerful processor and stunning camera features.\\nAdvertisement:\\nThe new model is the first to feature a 5.5-inch display, a Qualcomm Snapdragon 810 processor, 4GB of RAM, and a 13MP rear camera with a f/2.0 aperture. The phone also features a fingerprint sensor, a 3,000mAh battery, and a 3,000mAh removable battery. The phone will be available in two colors: black and white.\\nThe phone will be available in China starting on September 1st, and will be priced at 2,499 yuan (about $400).']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_ads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeQjiJq53EnO"
      },
      "source": [
        "## Using Greedy approach-\n",
        "\n",
        "With Greedy search, the word with the highest probability is predicted as the next word:\n",
        "\n",
        "### $w_t=argmax_wP(w|w_1:_t-_1)$\n",
        "\n",
        "Beam search is essentially Greedy Search but the model tracks and keeps num_beams of hypotheses at each time step, so the model is able to compare alternative paths as it generates text. We can also include a n-gram penalty by setting no_repeat_ngram_size = 3 which ensures that no 3-grams appear thrice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Siga5jOt4HRo"
      },
      "outputs": [],
      "source": [
        "def generate_advertisement_greedy(product_description):\n",
        "    input_text = \"Product: \" + product_description + \"\\nAdvertisement:\"\n",
        "\n",
        "    # Encode input text- use number of beams, ngram size\n",
        "    input_ids = tokenizer.encode(input_text, num_beams = 7,no_repeat_ngram_size=3,num_return_sequences=5,early_stopping = True,return_tensors=\"tf\")\n",
        "\n",
        "    # Generate text\n",
        "    output = model.generate(input_ids, max_length=150)\n",
        "\n",
        "    # decode the ids back into text\n",
        "    generated_ads = []\n",
        "    for sample in output:\n",
        "        generated_ad = tokenizer.decode(sample, skip_special_tokens=True)\n",
        "        generated_ads.append(generated_ad)\n",
        "\n",
        "    return generated_ads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOJ43Dbx4xQN",
        "outputId": "9da9df9b-ce52-4a94-e25d-f71346fdd3c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Keyword arguments {'num_beams': 7, 'no_repeat_ngram_size': 3, 'num_return_sequences': 5, 'early_stopping': True} not recognized.\n"
          ]
        }
      ],
      "source": [
        "generated_ads_greedy = generate_advertisement_greedy(product_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vYYBYNY43Qo",
        "outputId": "8406e0b5-8b32-4758-af0d-c44198114513"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Product: Introducing our latest smartphone model, with a powerful processor and stunning camera features.\\nAdvertisement:\\nThe new model is the first to feature a 5.5-inch display, a Qualcomm Snapdragon 810 processor, 4GB of RAM, and a 13MP rear camera with a f/2.0 aperture. The phone also features a fingerprint sensor, a 3,000mAh battery, and a 3,000mAh removable battery. The phone will be available in two colors: black and white.\\nThe phone will be available in China starting on September 1st, and will be priced at 2,499 yuan (about $400).']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_ads_greedy"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
